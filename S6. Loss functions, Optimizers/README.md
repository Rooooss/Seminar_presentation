# 학습 관련 기법 [1] - Loss functions, Optimizers

## Abstract

- 키워드 : MAE, MSE, Cross-entropy, GD, SGD, Momentum, NAG, Adagrad, RMSProp, Adadelta, Adam, Nadam

- 한줄 소개 : 신경망 학습에 필요한 개념 중에서 기울기를 구하는 데에 필요한 loss function 과, 기울기를 학습에 반영하는 방법인 optimizer에 대해 설명

## References

- 5 Regression Loss Functions All Machine Learners Should Know [link](https://heartbeat.fritz.ai/5-regression-loss-functions-all-machine-learners-should-know-4fb140e9d4b0)
- 자습해도 모르겠던 딥 러닝, 머리속에 인스톨 시켜드립니다. [link](https://www.slideshare.net/yongho/ss-79607172)
- Gradient Descent Optimization Algorithms 정리 [link](http://shuuki4.github.io/deep%20learning/2016/05/20/Gradient-Descent-Algorithm-Overview.html)
- An overview of gradient descent optimization algorithms [link](http://ruder.io/optimizing-gradient-descent/index.html)


